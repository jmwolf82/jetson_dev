{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06923de4-b04a-4194-979f-4afcf07490db",
   "metadata": {},
   "source": [
    "## PyTorch MNIST CNN Example on Jetson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5225f234-773b-4e14-9b22-514e3b29ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwolf/torch/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "#import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96185949-d9e0-42b5-9251-c1559a9989ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_path = './'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "mnist_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path, train=True,\n",
    "    transform=transform, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221077b4-9b17-4e25-a616-31ecde52b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6652ca3d-7dda-4f93-bb50-1775cb522fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_valid_dataset = Subset(mnist_dataset,\n",
    "                             torch.arange(10000))\n",
    "\n",
    "mnist_train_dataset = Subset(mnist_dataset,\n",
    "                             torch.arange(\n",
    "                                 10000,\n",
    "                                 len(mnist_dataset)\n",
    "                             ))\n",
    "\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path, train=False,\n",
    "    transform=transform, download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d70ea00-1281-4c0c-891c-6ae8454e10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset,\n",
    "                      batch_size,\n",
    "                      shuffle=True)\n",
    "valid_dl = DataLoader(mnist_valid_dataset,\n",
    "                      batch_size,\n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cedfe6aa-da21-4ff0-9299-f22666f2cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module(\n",
    "    'conv1',\n",
    "    nn.Conv2d(\n",
    "        in_channels=1, out_channels=32,\n",
    "        kernel_size=5, padding=2\n",
    "    )\n",
    ")\n",
    "# Layer 2 reLU\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "\n",
    "# Layer 3 Pooling\n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "# Layer 4 CNN\n",
    "model.add_module(\n",
    "    'conv2',\n",
    "    nn.Conv2d(\n",
    "        in_channels=32, out_channels=64,\n",
    "        kernel_size=5, padding=2\n",
    "    )\n",
    ")\n",
    "\n",
    "# Layer 5 reLU\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "\n",
    "# Layer 6 Pooling\n",
    "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "# Layer 7 Flatten\n",
    "model.add_module('flatten', nn.Flatten())\n",
    "# x = torch.ones((4, 1, 28, 28))\n",
    "# print(model(x).shape)\n",
    "\n",
    "# Layer 8 Fully Connected\n",
    "model.add_module('fc1', nn.Linear(3136, 1024))\n",
    "\n",
    "# Layer 9 reLU\n",
    "model.add_module('relu3', nn.ReLU())\n",
    "\n",
    "# Layer 10 Dropout\n",
    "model.add_module('dropout', nn.Dropout(p=0.5))\n",
    "\n",
    "# Layer 11 Fully Connected\n",
    "model.add_module('fc2', nn.Linear(1024, 10))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507e46e6-0844-46d3-bd99-62f2cdc0104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a350291c-49d7-4f26-b965-8ac347d2e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item() * y_batch.size(0)\n",
    "            is_correct = (\n",
    "                    torch.argmax(pred, dim=1) == y_batch\n",
    "            ).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                loss_hist_valid[epoch] += loss.item() * y_batch.size(0)\n",
    "                is_correct = (\n",
    "                        torch.argmax(pred, dim=1) == y_batch\n",
    "                ).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "\n",
    "        print(f'Epoch {epoch + 1} accuracy: '\n",
    "              f'{accuracy_hist_train[epoch]:.4f} val_accuracy: '\n",
    "              f'{accuracy_hist_valid[epoch]:.4f}')\n",
    "    return loss_hist_train, loss_hist_valid, \\\n",
    "        accuracy_hist_train, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18d500c1-ca91-4fc4-91d3-2ebbba2c6650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 accuracy: 0.9504 val_accuracy: 0.9810\n",
      "Epoch 2 accuracy: 0.9837 val_accuracy: 0.9865\n",
      "Epoch 3 accuracy: 0.9890 val_accuracy: 0.9828\n",
      "Epoch 4 accuracy: 0.9916 val_accuracy: 0.9884\n",
      "Epoch 5 accuracy: 0.9933 val_accuracy: 0.9885\n",
      "Epoch 6 accuracy: 0.9949 val_accuracy: 0.9899\n",
      "Epoch 7 accuracy: 0.9953 val_accuracy: 0.9896\n",
      "Epoch 8 accuracy: 0.9956 val_accuracy: 0.9881\n",
      "Epoch 9 accuracy: 0.9962 val_accuracy: 0.9895\n",
      "Epoch 10 accuracy: 0.9969 val_accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "num_epochs = 10\n",
    "hist = train(model, num_epochs, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f0c47-87e0-4d8a-ace3-72b5cfacd81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c980a-aafb-4e6c-abb6-b8fbdce104b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1e02a-b0ea-42aa-ab4f-a138f75c22c5",
   "metadata": {},
   "source": [
    "#### Conv2D Shape:\n",
    "<code>torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)<code>\n",
    "<br>\n",
    "<code>nn.Conv2d(in_channels, out_channels, kernel_size, padding)<code>    \n",
    "- N: batch size\n",
    "- C: number of channels\n",
    "- H: height of input planes in pixels\n",
    "- W: width in pixels\n",
    "<br>\n",
    "- Input: (N, Cin, Hin, Win) or (Cin, Hin, Win)\n",
    "- Output: (n, Cout, Hout, Wout) or (Cout, Hout, Wout)\n",
    "<br>\n",
    "- Hout = ((Hin + 2 * padding - dilation x (kernel_size -1) -1) / stride) + 1\n",
    "- Wout = ((Win + 2 * padding - dilation x (kernel_size -1) -1) / stride) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33786633-3c7f-442e-81d7-570cb45afb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((28 + 2 * 2 - 1 * (5-1)-1)/2)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb0e78-24fe-4778-b6ba-03bae27f14d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
